<!DOCTYPE HTML>
<HTML>
	<HEAD>
		<TITLE>
		 	COMP 417 project
		</TITLE>
		<style>
		body {
			margin: 5% 20%;
			font-size: 16pt;
		}
		p.abstract {
		    font-style: italic;
			margin-left: 30px;
		}
		figcaption{
			font-style: italic;
		}

		h1, h2, h3 {
		    font-family: Arial, Helvetica, sans-serif;
		}
		figure{
			text-align: center;
		}
		span.author{
			font-size: 14pt;
		}
		table{
			border:1px solid black;
		}
		td{
			min-width: 100px;
		}
		img.flow{
			/*width:38%;
			height:38%;
			margin-right:-6%;*/
			float:left;
			display: inline-block;
		}
		div.scollableFigure{
			overflow-x:scroll; 
			overflow-y:hidden;
			height:605px;
			width: 100%;
		}
		div.scollableFigure table{
			border: 0px;
		}
		div.scollableFigure td{
			height:600px;
		}
		</style>
		<head>
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
		</script>
		<script type="text/javascript"
		  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
		<script>
			$("a[href='#top']").click(function() {
			  $("html, body").animate({ scrollTop: 0 }, "slow");
			  return false;
			});
		</script>
</head>
	</HEAD>
<BODY>
	<center>
		<H1>
			Study on Network Calibration
		</H1>
		<span class="author">by Yi Tian Xu <br>
		Undergraduate in Statistics and Computer Science <br>
		@McGill University, December 2014</span>
	</center>
	<P class="abstract">
		This project outlines the idea proposed by Dimitrios Makris, Tim Ellis and James Black through their paper "<a href="http://www.cim.mcgill.ca/~dudek/417/Papers/sensenet-markis-e-b.pdf" target="blank">Briging the Gaps between Camera</a>" published in 2004. This
		project was required work for the 
		<a href="http://www.cim.mcgill.ca/~dudek/417.html">
		Introduction to Robotics
		</a>
		taught by <a href="http://www.cim.mcgill.ca/~dudek">Gregory Dudek</a>.
	<P>

<h2>Content</h2>
<ol>
	<li><a href="#1">Introduction</a></li>
	<li><a href="#2">Theory</a></li>
	<li><a href="#3">Implementation</a>
		<ol>
			<li><a href="#31">Data Classification</a></li>
			<li><a href="#32">Parameter Estimation</a></li>
			<li><a href="#33">Interpretation</a></li>
		</ol></li>
	<li><a href="#4">Experiment</a></li>
		<ol>
			<li><a href="#41">Design</a></li>
			<li><a href="#42">Result</a></li>
		</ol></li>
	<li><a href="#5">Conclusion</a></li>
</ol>

<a name="1"></a><h2>Introduction</h2>
<p>In an environment partially monitored by cameras, an intelligent surveillance system may  benefit itself by knowing how to track targets transiting through the blind regions between two spatially adjacent cameras. Such system may allow continuous tracking of targets and generation of complete activity records. </p>

<p>Makis et al at Kingston University have put a considerable effort on solving single camera tracking and matching tracks in overlapping camera views. Meanwhile, some methods have been proposed by other researchers to track single object through multiple camera views. Notably, Javed et al suggest to correspond the individual tracks of a target using feature matching by maximizing the posterior probability of the spatio-temporal and color appearance of the target. <a href="#r2">[2]</a> However, color is not guaranteed to be always reliable to match targets across multiple cameras.</p>

<p> An alternative approach is to learn and build a model of the environment and of the camera connectivity, enabling the system to predict the behavior its targets. This allows one camera to "handover" the track to the next camera as the target move across the two, and thus avoids the need of establishing any correspondence. This model can carry spacial (topology) and temporal (time taken for targets to move between views) information of the network.
</p>

<p>The topology of the camera can be determined by using calibrated cameras, whose transformation function of pixel coordinates into 3D coordinates is already defined. If the coordinate system in which calibration is done is common to all the cameras, a geometric analysis of each camera views would then allows spatial adjacency to be established. However, in a large network of cameras, it would be preferable if the system can calibrate itself automatically. Furthermore, a common coordinate system might not be necessary since establishing spatial adjacency requires simply the knowledge of the cameras position relative to each other.</p> 

<p>This project investigates on unsupervised learning method, "network calibration", proposed by Makris et al, that establishes links between camera views without any requirement of correspondence of target tracks and pre-calibration. This method trains itself on a dataset of observed target trajectories and infers the topology of the camera network based on statistics. <a href="#r1">[1]</a> We conducted a series of experiments based on simulations to test the completeness of the method.
</p>
<a href='#top'>[top]</a>

<a name="2"></a><h2>Theory</h2>
<p>Each camera view has a set of zones describing where targets enter or leave. These entry/exit zones can be represented as nodes in a network. Each edge between two nodes denote an transition which is either visible or invisible to the cameras. Figure 1 shows an exmples of such network with two zones. </p> 

<figure>
	<img src="image/graphmodel.png">
	<figcaption><b>Figure 1</b> The network showing entry zone $i$ and exit zone $j$.</figcaption>
</figure> 

<p>The transition probability of a target from zone $i$ to zone $j$ is $\alpha_{ij} = \int \alpha_{ij}(\tau) d\tau$ where $\alpha_{ij}(\tau)$ for each $\tau$ is the probability of transiting within a time $\tau$. Any region outside of zone $i$ and $j$ is represented by a virtual node $k$. Targets may move from zone $i$ to somewhere else with probability $\alpha_{ik}$ and enter zone $j$ from somewhere else with rate $\pi_{j}$. The transitions fulfil

\begin{equation*}\sum_{Z} \alpha_{iZ} = 1\end{equation*}

A target disappearing at zone $i$ and reapearing at zone $j$ will kindle two signals to the cameras. These signals are modeled as Bernoulli processes, $N_i$ and $M_j$ respectively, and they are assumed to be individually and jointly stationary. That is, at any time $t$, the probability of seeing a target appearing at zone $i$ is 

\begin{equation*}p_n = p(n_i(t) = 1) = E[N_i]\end{equation*}

and the probability of seen a target dissapearing at zone $j$ is

\begin{equation*}p_m = p(m_j(t) = 1) = E[M_j]\end{equation*}

If zone $i$ and zone $j$ are adjacent or overlapping, then their associated signals are correlated, i.e.: if a target appears in zone $i$, there is a higher chance that it will appear in zone $j$ after some time $\tau^*$. This implies that the transition probability $\alpha_{ij}(\tau^*)$ is much higher than $\alpha_{ij}(\tau) \ \forall \tau \neq \tau^*$. Such links between zones can be detected by estimating the cross-correlation, defined as

\begin{equation*}R_{ij}(\tau) = E[n_i(t) m_j(t+\tau)]\end{equation*}

and the covariance, 

\begin{equation}\mbox{Cov}_{ij}(\tau) = R_{ij}(t) - p_np_m\end{equation}

If $\int$Cov$_{ij}(\tau) d\tau = 0$, then the signals are independent. Links formed by dependent zones are called "valid". The transition probability can be estimated using

\begin{equation}\alpha_{ij}(\tau) = \mbox{Cov}_{ij}(\tau) / p_n(1-p_n)\end{equation}

</p>
<a href='#top'>[top]</a>

<a name="3"></a><h2>Implementation</h2>
<p>The entry/exit zones are known before starting Network Calibration. They can be leant using Expectation-Maximization on a dataset of trajectories as did Makris et al for their implementation, which is presented in one of their preious works. <a href="#r3">[3]</a> Let $Z$ be the set of learnt zones. Each signal $N_i$ from some zone $i\in Z$ is modeled as a Gaussian distribution with mean $\boldsymbol\mu_i$, covariance $\boldsymbol\Sigma_i$ and a prior probability $p_i = p_n$. Together, the network is represented by a Gaussian Mixture $\theta = \{\boldsymbol\mu_i, \boldsymbol\Sigma_i, p_i | i\in Z\}$. </p>
<p>Further observations of trajectories are done by the cameras to learn the topology. This process is mainly divided into three parts: data classification, parameter estimation, interpretation. </p>

<a name="31"></a><h3>Data Classification</h3>
<p>For each signal $x$ related to an appearance/disappearance of a target, Maximum-a-Posteriori (MAP) is used to estimate which entry/exit zone $x$ belongs to using the following equations.

\begin{equation*}\mbox{most likely zone = arg}\max_{i\in Z} (p(i|x,\theta))\end{equation*}

where

\begin{align}
	&p(i|x,\theta) = \eta p_i p(x|i)\\
	&p(x|i) = \frac{1}{\sqrt{2\pi|\boldsymbol\Sigma_i|}} \exp{\left(-\frac{1}{2}(x - \boldsymbol\mu_i)^\top \boldsymbol\Sigma_i^{-1}(x - \boldsymbol\mu_i)\right)}
\end{align}

Equation (3) follows from Bayes Rule; $\eta = \sum_{j\in Z} p_j p(x|j)$ is the normalization factor. Equation (4) describes the probability of having a signal at zone $i$, which is assumed to follow the Gaussian distribution. The logarithm of the probabilities is used instead and the equations can be simplified into the following.

\begin{equation*} p(i|x,\theta) \propto \log{(p_i p(x|i))} - \frac{1}{2}\log{|\boldsymbol\Sigma_i|} -\frac{1}{2}(x - \boldsymbol\mu_i)^\top \boldsymbol\Sigma_i^{-1}(x - \boldsymbol\mu_i)\end{equation*}
</p> 

<a name="32"></a><h3>Parameter Estimation</h3>
<p>The cross-correlation function $R_{ij}(\tau)$ is estimated for $-T\leq \tau \leq T$ and are implemented as counters. The parameter $T$ defines the time-search window. When an appearance event at zone $i$ is observed at some time $t_1$, the method searches for a disappearance event at zone $j$ at time $t_2$ such that $t_2 \in [-T+t_1, T+t_1]$. It then increment $R_{ij}(\lfloor t_2 - t_1 \rceil)$ by 1, where $\lfloor t_2 - t_1 \rceil = \lfloor t_2 - t_1 + 0.5 \rfloor$ is the time difference rounded to the nearest integer.</p>
<p>After gathering enough data to shape the cross-correlation functions, the covariance can be then estimated. As the stationary assumption about the signal is wrong, equation (1) is replaced by 

\begin{equation*}\mbox{Cov}_{ij}(\lfloor\tau\rceil) = R_{ij}(\lfloor\tau\rceil) - \mbox{median}_{\tau}R_{ij}(\tau)\end{equation*}

<p>If the covariance $C_{ij}(\lfloor\tau\rceil)$ has a clear peak at some $\lfloor\tau\rceil$, then $\lfloor\tau\rceil$ represents the most popular transition time period between zone $i$ and $j$, implying that the signals from these two zones are correlated, i.e.: they form a valid link. A threshold defined as 

\begin{equation} thr = E[R_{ij}(\tau)] - \omega\sqrt{V[R_{ij}(\tau)]}\end{equation}

is used to filter out the peaks that are not significant. Correlated entry/exit pairs are assumed to have interconnected pathways, each with transition probability that can be estimated with equation (2) and by enforcing the constraint

\begin{equation*}0 < \int \alpha_{ij}(\tau) d\tau < 1\end{equation*} 

However, if the most popular transition time is strictly negative, the following equation is used instead.

\begin{equation*}\alpha_{ji}(\tau) = \mbox{Cov}_{ij}(\tau) / p_m(1-p_m)\end{equation*}</p>

<a name="33"></a><h3>Interpretation</h3>
<p>The topology of the cameras can be inferred by the set of valid links and their transition times. Considering two zones $i$ and $j$, each from a different camera view, if the transition time form $i$ to $j$ is approximately zero, then the two zones are overlapping. If the transition time is strictly positive, then targets can move from $i$ to $j$ through an unseen path. Finally, if the transition time is strictly negative, then targets enter $j$ before they leave $i$, implying that both zones are either partially or completely visible on both cameras.</p>

<a href='#top'>[top]</a>

<a name="4"></a><h2>Experiment</h2>
<p>Makris et al tested their method on a set of 6 cameras monitoring street passengers (pedestrains and vehicles) for a period of 13 hours. Their result showed that Network Calibration can successfully determine the topology of the cameras as discussed in the previous section.</p>

<p>We decide to carry an experiment on the completeness of their method. More specifically, we are interested in knowing if Network Calibration can find all the valid links. Theoretically, if there's a transition between two zones, regardless of how small its probability is, running Network Calibration long enough will eventually lead to the discovery of that link. However, as running time is restricted in real world applications, the question of how much data is enough arises. It may be intuitive to think that to find a valid link, the zones of that link need to be detected and signals from these zones must be observed when performing Network Calibration. Yet, as the method is correspondence-free, trajectory information are discarded and thus one observation of a target moving along that link is not enough for the method to detect that link.</p>

<a name="41"></a><h3>Design</h3>
<p>We construct a computer simulated environment with two cameras. For simplicity, the entry/exit zones, their probability distribution and parameters are fixed, and all targets start from one zone and move to the others in a random walk fashion.</p>
<figure>
	<img src="image/exp1.png">
	<figcaption><b>Figure 2</b> The simulated setting showing the viewfield of the two cameras and their entry/exit zones. </figcaption>
</figure>
<p>During the simulation, targets are generated with a random entering time and a position sampled from the distribution at zone 1. Then, they move to the next according to the transition probabilities and a speed drawn from a fixed distribution. Tests are done on varying the transition probability $\alpha_{13}$ (and $\alpha_{12}$) and the number of sample for learning the zones and the topology. The other transition probabilities are fixed at 1.0. For simplicity, we assume that the number of sample is the same for both learning systems. We also assume that the zones are know up to their signal distribution. Thus, each simulation first generates data to learn the parameters defining the signal distribution for each zone, then produced the data to infer topology.</p> 
<p>Since the generation of signals is not ordered by time, we do not run Network Calibration at the same time as we gather data, unlike how it was originally designed.</p>

<a name="42"></a><h3>Result</h3>
<p>For each combination of $\alpha_{13} \in \{0.01, 0.25, 0.50, 0.75, 0.99\}$ and sample size $n \in \{100, 500, 1000, 2000, 3000, 4000, 5000\}$ is tested 30 times, and results gathered based on the number of times a transition probability is found. As most links have transition time around 5 seconds in the setting, we choose a search window of $T=15$. We choose a threshold $thr = E[R_{ij}(\tau)]$ to show as many potential candidates for the detected transition probabilities without tolerating too much noise. Figure 3 shows how often $\alpha_{ij}(\tau)$ are found for each detected link. </p>
<figure>
	<div class="scollableFigure">
		<table></tr>
				<td><img class="flow" src="image/0.01_100.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_500.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_1000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_2000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_3000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_4000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.01_5000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_100.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_500.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_1000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_2000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_3000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_4000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.25_5000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_100.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_500.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_1000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_2000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_3000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_4000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.5_5000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_100.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_500.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_1000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_2000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_3000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_4000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.75_5000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_100.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_500.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_1000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_2000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_3000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_4000.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/0.99_5000.jpeg" style="height:100%;"></td>
		</tr></table>
	</div>
	<table>
		<caption>Legend</caption><tr>
			<td><b>Number</b></td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
		</tr><tr>
			<td><b>Link</b></td>
				<td>1 &#10141; 1</td>
				<td>1 &#10141; 4</td>
				<td>1 &#10141; 5</td>
				<td>1 &#10141; 3</td>
				<td>1 &#10141; 2</td>
				<td>4 &#10141; 1</td>
				<td>4 &#10141; 4</td>
				<td>4 &#10141; 5</td>
				<td>4 &#10141; 3</td>
		</tr>
	</table>
	<table>
		<tr>
				<td>10</td>
				<td>11</td>
				<td>12</td>
				<td>13</td>
				<td>14</td>
				<td>15</td>
				<td>16</td>
				<td>17</td>
				<td>18</td>
				<td>19</td>
		</tr><tr>
				<td>4 &#10141; 2</td>
				<td>5 &#10141; 1</td>
				<td>5 &#10141; 4</td>
				<td>5 &#10141; 5</td>
				<td>5 &#10141; 3</td>
				<td>5 &#10141; 2</td>
				<td>3 &#10141; 1</td>
				<td>3 &#10141; 4</td>
				<td>3 &#10141; 5</td>
				<td>3 &#10141; 3</td>
		</tr>
	</table>
	<table>
		<tr>
				<td>20</td>
				<td>21</td>
				<td>22</td>
				<td>23</td>
				<td>24</td>
				<td>25</td>
		</tr><tr>
				<td>3 &#10141; 2</td>
				<td>2 &#10141; 1</td>
				<td>2 &#10141; 4</td>
				<td>2 &#10141; 5</td>
				<td>2 &#10141; 3</td>
				<td>2 &#10141; 2</td>
		</tr>
	</table><br>
	<figcaption><b>Figure 3</b> Test result for different sample sizes and transition probabilities. Links with no data point indicates that only signals have been observed from their corresponding zone with a time elapsed of at most 15 seconds. (Note that there is a total of 35 images in the scrollable table).</figcaption>
</figure>

<p>From the result, our initial hypothesis that links with low transition probability  $\alpha_{13}$ have less chance to be detected appears to be wrong. When the probability of transiting from zone 3 to zone 4 (link #17 on Figure 3) is set to 0.01, the method finds the link at least 50% of the time for sample size above 1000. When set to 0.25, the method achieves to find the same transition probability for that link with a specific transition time for all the 30 runs and sample size at least 500.</p>

<p>While it is apparent that small sample size affects the ability for the method to detect all the zones, when a link has high transition probability, a sample size too large may overload the system with too much signal data. As observed for link 3-4, when the  $\alpha_{13}$ is raised higher than 0.5, the method inundates the cross-correlation vector for that link, inflating the significance of invalid transition times. As the threshold to filter the covariance is defined according to the mean and variance of the cross-correlation (see equation 5), the peak for that link therefore looses its significance. The similar situation is observed for link 1-2 (link #5 on Figure 3), as each simulated trajectory must start from zone 1. This link is almost never detected regardless of its transition probability.</p>
<p>As targets much cross link 4-5 (link #8 on Figure 3) after crossing link 3-4 in the simulation, these two links are correlated. In the result, this correlation is also evident. However, redundant links such as 1-3, 1-4, 1-5 and 3-5 should also be correlated with link 4-5. As discussed previously, any link related with zone 1 is rarely detected due to the crowdedness of the signals at zone 1. On the other hand, 1-4 and 3-5 are entry-entry or exit-exit links. Since the method only detect exit-entry links (which is adequate for detecting connections between camera view), unless some signals are misclassified when performing MAP, detecting these links would be impossible.</p>
<p>Arguably, the threshold affects how the method perform in detecting links correlated with link 3-4. However, decreasing the threshold would also increase the significance for the invalid links. In many cases, such links are detected more often or found to have more significant covariance peak than some valid links, possibly due to noise and misclassification.</p>
<p>On the inspection of possible misclassification, we found that the percent accuracy for classifying a signal to the zone that it was generated form varies according to $\alpha_{13}$. When this rate is low, the chance of observing signal from other zones than 1 and 2 is lower, resulting zones 1 and 2 to be more popular. Thus, classification when there are mainly two choices is highly successful. When the variety of zone observed is high, there are more chance of matching a signal with the wrong zone. Figure 4 shows this result.</p>

<figure>
	<div class="scollableFigure">
		<table></tr>
				<td><img class="flow" src="image/accuracy0.01.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/accuracy0.25.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/accuracy0.5.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/accuracy0.75.jpeg" style="height:100%;"></td>
				<td><img class="flow" src="image/accuracy0.99.jpeg" style="height:100%;"></td>
		</tr></table>
	</div><br>
	<figcaption><b>Figure 4</b> The percentage accuracy of classifying a signal for each transition probability $\alpha_{13}$ and sample size to train the classifier. Result from each graph is the average of 300 runs, each classifying 1000 signal data. (Note that there is a total of 5 images in the scrollable table.)</figcaption>
</figure>

<p>Linking back to our main result, misclassification may explain why certain invalid links, such as 3-3 and 4-4, are found more often when the $\alpha_{13}$ is high. A possible scenario is that some signals from zone 4 is classified to zone 3, and vice-versa. Since there is a valid link between the two zone, the method would find a peak for 3-3 and 4-4. However, this scenario is only valid if signals for appearance and disappearance of target are not distinguished by whether the zones to which they are associated to are entry zone or exit zones. In our implementation, we assumed that the distinction can be made by observing the signal itself. In the original paper, the authors did not clarify on this part of their design. </p>

<p>The link 3-5 is occasionally detected when $\alpha_{13}$ is high. In this case, misclassification appears to enable the method to detect valid entry-entry link, which otherwise can never be detected. Entry-entry and exit-exit links that are redundant theory, may perhaps occasionally serve as a substitute to exit-entry links that are not detectable.</p>

<p>Figure 5 shows how varying the variance term in the threshold function affects the output of the method. When threshold is decremented by half of the variance, link 3-4 can be detected at most 50% of the time. Yet, some invalid links, such as 3-3, is amplified, and link 4-5 is still not detected. When the threshold is incremented by half of the variance, link 3-3 is suppressed - as well as every other link.</p>

<figure>
	<img class="flow" src="image/-0.5_1000_solo.jpeg" style="height:50%;width:50%;">
	<img class="flow" src="image/0.5_1000_solo.jpeg" style="height:50%;width:50%;">
	<figcaption><b>Figure 5</b> Number of times a transition probability with a transition time for a link is found when the sample size if 100 and $\alpha_{13}$ is 0.75 and $\omega\in \{-0.5, 0.5\}$. </figcaption>
</figure>

<a href='#top'>[top]</a>

<a name="5"></a><h2>Conclusions </h2>
<p>In our experiment, we constructed a scene with 2 cameras with a simple model for the behavior of the targets. Despite that it is a simulation, we were able to explore on some edge cases where Network Calibration may have difficulty with. Mainly, when signals from an exit-entry zone pair is crowded, the peak in the correlation, if it exists, is buried in a sea of inflated noise. Decreasing the threshold is not the ideal solution as it may also enable the method to fish up small peaks from invalid links.</p>

<p>On the other side, our investigation on the effect of misclassified signals may suggest to raise up the threshold in some cases. Due to the reasonably high accuracy of MAP in our experiment, it may be possible that links detected by misclassification can be filtered out with a higher threshold. Yet, in a scenario where there are much more camera zones, misclassification rate is likely to grow. In such case, the choice of threshold may not be the best solution; it affects the detectability of popular links, thus cannot be easily increased. Nonetheless, if leaving misclassified signals lurking in the mode, the method may in some cases establish a wrong connection between two close cameras. In a setting where two camera view are separated by a wall, for example, the Gaussian assumption of the signals implies that the zones are extended infinitely far. A small accuracy error may enable the targets in the model to move through the wall. It may possible to improve the method by confining the zone within the boundary of the camera views. However, in a real experiment, noise from camera sensor may possibly cause signals to be detected beyond the bound.</p>

<p>An alternative way to improve the method might be to replace the threshold by a multiple thresholds, or by another function that takes into account not only the mean and variance of the cross-correlation, but also the sample size, the number of zones and the number or the rate of signal data recorded for a candidate link. Then, optimization of the threshold through empirical observation is a possibility for further improvement. As the threshold depends on many parameters that are not stationary and invariant in different conditions, it is unclear whether results from a particular environment and camera setup can be easily generalized.</p>

<p>Another way might be to inspect entry-entry and exit-exit links and connect cameras according to a link-zone ratio, i.e.: if most zone is a camera view are detected to have a link with the zones in another camera view, then the two camera are likely to be connected. This may give a purpose for the redundant links that the authors are concerned for in their paper. However, if the detected links are later on used to predict the behavior of targets, then a method to remove redundant links is still be required.</p>

<p>Overall, the method is simple and easy to implement. Its main benefit is that it is completely unsupervised, correspondence-free, and requires no per-calibration for the cameras. On the other hand, the trajectory information discarded during the sampling is a non-negligible trade-off with the sampling size. As in the method by Javed et al, the training time in their experiment took 10 minutes <a href="#r2">[2]</a>, while the data collection of Network Calibration, in its creators' experiment, lasted 13 hours.</p> 

<a name="6"></a><h2>References</h2>
<p><a name="r1"></a>[1] Makris, D.; Ellis, T.; Black, J. "Bridging the gaps between cameras",  Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, On page(s): II-205 - II-210 Vol.2 Volume: 2, 27 June-2 July 2004 </p>
<p><a name="r2"></a>[2] Omar Javed, Zeeshan Rasheed, Khurram Shafique, Mubarak Shah, "Tracking Across Multiple Cameras With Disjoint Views", IEEE International Conference on Computer Vision, Nice, France, 2003. <a href="http://visionnas2.cs.ucf.edu/papers/javed_iccv03.pdf">http://visionnas2.cs.ucf.edu/papers/javed_iccv03.pdf</a></p>
<p><a name="r3"></a>[3] D. Makris, T.J. Ellis, "Automatic Learning of an Activity-Based Semantic Scene Model", IEEE International Conference on Advanced Video and Signal Based Surveillance, Miami, FL, USA, pp. 183-188. July 2003.  </p>

<a href='#top'>[top]</a>
</BODY>
</html>
