<!DOCTYPE HTML>
<HTML>
	<HEAD>
		<TITLE>
		 	COMP 417 project
		</TITLE>
		<style>
		body {
			margin: 5% 25%;
			font-size: 16pt;
		}
		p.abstract {
		    font-style: italic;
			margin-left: 30px;
		}

		h1, h2, h3 {
		    font-family: Arial, Helvetica, sans-serif;
		}
		figure{
			text-align: center;
		}
		span.author{
			font-size: 14pt;
		}
		</style>
		<head>
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		  // MathJax.Hub.Register.StartupHook("AsciiMath Jax Config",function () {
		  //   var AM = MathJax.InputJax.AsciiMath.AM;
		  //   AM.symbols.push(
		  //     {input:"mathbi", tag:"mstyle", atname:"mathvariant", atval:"bold-italic",
		  //      output:"mathbi", tex:null, ttype:AM.TOKEN.UNARY}
		  //   );
		  // });
		  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
		</script>
		<script type="text/javascript"
		  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
		<script>
			$("a[href='#top']").click(function() {
			  $("html, body").animate({ scrollTop: 0 }, "slow");
			  return false;
			});
		</script>
</head>
	</HEAD>
<BODY>
	<center>
		<H1>
			Study on Network Calibration
		</H1>
		<span class="author">by Yi Tian Xu <br>
		Undergraduate in Statistics and Computer Science <br>
		@McGill University, December 2014</span>
	</center>
	<P class="abstract">
		This project outlines the idea proposed by Dimitrios Makris, Tim Ellis and James Black through their paper "<a href="http://www.cim.mcgill.ca/~dudek/417/Papers/sensenet-markis-e-b.pdf" target="blank">Briging the Gaps between Camera</a>" published in 2004. This
		project was required work for the 
		<a href="http://www.cim.mcgill.ca/~dudek/417.html">
		Introduction to Robotics
		</a>
		taught by <a href="http://www.cim.mcgill.ca/~dudek">Gregory Dudek</a>.
	<P>

<h2>Content</h2>
<ol>
	<li><a href="#1">Introduction</a></li>
	<li><a href="#2">Theory</a></li>
	<li><a href="#3">Implementation</a>
		<ol>
			<li><a href="#31">Data Classification</a></li>
			<li><a href="#32">Parameter Estimation</a></li>
			<li><a href="#33">Interpretation</a></li>
		</ol></li>
	<li><a href="#4">Experiment</a></li>
	<li><a href="#5">Conclusion</a></li>
</ol>

<a name="1"></a><h2>Introduction</h2>
<p>To track objects in an environmnet partially monitored by cameras, an intelligent surveillance system need to know how to deal with targets transiting through the blind regions between two spatially adjacent cameras. Such system would be able to continuously track targets and to generate complete target activity records. </p>

<p>Past research has been done on single camera tracking and matching tracks in overlapping camera views. Some methods have been proposed to track single object through multiple camera views. Notably, Javed et al suggest to correspond the individial tracks of a target using feature matching by maximizing the posterior probability of the spatio-temporal and color apparance of the target. <a href="#r2">[2]</a> However, color is not guaranteed to be always reliable to match targets across multiple cameras.</p>

<p> An alternative approach is to find a model of the environment and of the camera connectivity, enabling the system to predict the bahavior its targets. This allows one camera to "handover" the track to the next camera as the target move across the two, and thus avoids the need of establishing any correspondence. This model can carry spacial (topology) and temporal (time taken for targets to move between views) information of the network.
</p>

<p>The topology of the camera can be determined by using calibrated cameras, whose transformation function of pixel coordinates into 3D coordinates is already defined. If the coordinate system in which calibration is done is common to all the cameras, a geometric analysis of each camera views would then allows spatial adjacency to be established. However, in a large network of cameras, it would be preferable if the system can calibrate itself automatically. Furthermore, a common coordinate system might not be necessary since establishing spatial adjacency requires simply the knowledge of the cameras position relative to each other.</p> 

<p>This project inverstigates on unsupervised learning method, "network calibration",proposed by Makris et al, that estabilishes links between camera views without any requirement of correspondence of target tracks and pre-calibration. This method trains itself on a dataset of observed target trajectories and infers the topology of the camera network based on statistics. <a href="#r1">[1]</a>
</p>
<a href='#top'>[top]</a>

<a name="2"></a><h2>Theory</h2>
<p>Each camera view has a set of zones describing where targets enter or leave. These entry/exit zones can be represented as nodes in a network. Each edge between two nodes denote an transition which is either visibile or invisible to the cameras. Figure 1 shows an exmples of such network with two zones. </p> 

<figure>
	<img src="graphmodel.png" alt="Tempo-topographical model">
	<figcaption><b>Figure 1</b> The network showing entry zone $i$ and exit zone $j$.</figcaption>
</figure> 

<p>The transition probability of a target from zone $i$ to zone $j$ is $\alpha_{ij} = \int \alpha_{ij}(\tau) d\tau$ where $\alpha_{ij}(\tau)$ for each $\tau$ is the probability of transiting within a time $\tau$. Any region outside of zone $i$ and $j$ is represented by a virtual node $k$. Targets may move from zone $i$ to somewhere else with probability $\alpha_{ik}$ and enter zone $j$ from somewhere else with rate $\pi_{j}$. The transitions filful

\begin{equation*}\sum_{Z} \alpha_{iZ} = 1\end{equation*}

A target disappearing at zone $i$ and reapearing at zone $j$ will kindle two signals to the cameras. These signals are modeled as Bernoulli processes, $N_i$ and $M_j$ respectively, and they are assumed to be indvidually and jointly stationary. That is, at any time $t$, the probability of seeing a target appearig at zone $i$ is 

\begin{equation*}p_n = p(n_i(t) = 1) = E[N_i]\end{equation*}

and the probability of seen a target dissapearing at zone $j$ is

\begin{equation*}p_m = p(m_j(t) = 1) = E[M_j]\end{equation*}

If zone $i$ and zone $j$ are adjacent or overlapping, then their associated signals are correlated, i.e.: if a target appears in zone $i$, there is a higher chance that it will appear in zone $j$ after some time $\tau^*$. This implies that the transition probability $\alpha_{ij}(\tau^*)$ is much higher than $\alpha_{ij}(\tau) \ \forall \tau \neq \tau^*$. Such links between zones can be detected by estimating the cross-correlation, defined as

\begin{equation*}R_{ij}(\tau) = E[n_i(t) m_j(t+\tau)]\end{equation*}

and the covariance, 

\begin{equation}\mbox{Cov}_{ij}(\tau) = R_{ij}(t) - p_np_m\end{equation}

If $\int$Cov$_{ij}(\tau) d\tau = 0$, then the signals are independent. Links formed by dependent zones are called "valid". The transition probability can be estimated using

\begin{equation}\alpha_{ij}(\tau) = \mbox{Cov}_{ij}(\tau) / p_n(1-p_n)\end{equation}

</p>
<a href='#top'>[top]</a>

<a name="3"></a><h2>Implementation</h2>
<p>The entry/exit zones are known before starting Network Calibration. They can be leant using Expectation-Maximization on a dataset of trajectories as did Makris et al for their implementation, which is presented in one of their preious works. <a href="#r3">[3]</a> Let $Z$ be the set of learnt zones. Each signal $N_i$ from some zone $i\in Z$ is modeled as a Guassian distribution with mean $\boldsymbol\mu_i$, covariance $\boldsymbol\Sigma_i$ and a prior probability $p_i = p_n$. Together, the network is represented by a Gaussian Mixture $\theta = \{\boldsymbol\mu_i, \boldsymbol\Sigma_i, p_i | i\in Z\}$. </p>
<p>Further observations of trajectories are done by the cameras to learn the topology. This process is mainly divided into three parts: data classification, parameter estimation, interpretation. </p>

<a name="31"></a><h3>Data Classification</h3>
<p>For each signal $x$ related to an appearance/disappearance of a target, Maximum-a-Posteriori is used to estimate which entry/exit zone $x$ belongs to using the following equations.

\begin{equation*}\mbox{most likely zone = arg}\max_{i\in Z} (p(i|x,\theta))\end{equation*}

where

\begin{align}
	&p(i|x,\theta) = \eta p_i p(x|i)\\
	&p(x|i) = \frac{1}{\sqrt{2\pi|\boldsymbol\Sigma_i|}} \exp{\left(-\frac{1}{2}(x - \boldsymbol\mu_i)^\top \boldsymbol\Sigma_i^{-1}(x - \boldsymbol\mu_i)\right)}
\end{align}

Equation (3) follows from Bayes Rule; $\eta = \sum_{j\in Z} p_j p(x|j)$ is the normalization factor. Equation (4) decribes the probability of having a signal at zone $i$, which is assumed to follow the guassian distribution. The logarithm of the probabilities is used instead and the equations can be simplified into the following.

\begin{equation*} p(i|x,\theta) \propto \log{(p_i p(x|i))} - \frac{1}{2}\log{|\boldsymbol\Sigma_i|} -\frac{1}{2}(x - \boldsymbol\mu_i)^\top \boldsymbol\Sigma_i^{-1}(x - \boldsymbol\mu_i)\end{equation*}
</p> 

<a name="32"></a><h3>Parameter Estimation</h3>
<p>The cross-correlation function $R_{ij}(\tau)$ is estimated for $-T\leq \tau \leq T$ and are implemented as counters. When an appearance event at zone $i$ is observed at some time $t_1$, the method searches for a disappearance event at zone $j$ at time $t_2$ such that $t_2 \in [-T+t_1, T+t_1]$. It then increment $R_{ij}(\lfloor t_2 - t_1 \rceil)$ by 1, where $\lfloor t_2 - t_1 \rceil = \lfloor t_2 - t_1 + 0.5 \rfloor$ is the time difference rounded to the nearest integer.</p>
<p>After gathering enough data to shape the cross-correlation functions, the covariance can be then estimated. As the stationary assumption about the signal is wrong, equation (1) is replaced by 

\begin{equation*}\mbox{Cov}_{ij}(\lfloor\tau\rceil) = R_{ij}(\lfloor\tau\rceil) - \mbox{median}_{\tau}R_{ij}(\tau)\end{equation*}

<p>If the covariance $C_{ij}(\lfloor\tau\rceil)$ has a clear peak at some $\lfloor\tau\rceil$, then $\lfloor\tau\rceil$ represents the most popular transition time period between zone $i$ and $j$, implying that the signals from these two zones are correlated, i.e.: they form a valid link. A threashold defined as 

\begin{equation*} thr = E[R_{ij}(\tau)] - \omega\sqrt{V[R_{ij}(\tau)]}\end{equation*}

is used to filter out the peaks that are not significant. Correlated entry/exit pairs are assumed to have interconnected pathways, each with transition probability that can be estimated with equation (2) and by enforcing the constraint

\begin{equation*}0 < \int \alpha_{ij}(\tau) d\tau < 1\end{equation*} 

However, if the most popular transition time is strictly negative, the following equation is used instead.

\begin{equation*}\alpha_{ji}(\tau) = \mbox{Cov}_{ij}(\tau) / p_m(1-p_m)\end{equation*}</p>

<a name="33"></a><h3>Interpretation</h3>
<p>The topology of the cameras can be inferred by the set of valid links and their transition times. Considering two zones $i$ and $j$, each from a different camera view, if the transition time form $i$ to $j$ is approximately zero, then the two zones are overlapping. If the transition time is strictly positive, then targets can move from $i$ to $j$ through an unseen path. Finally, if the transition time is strictly negative, then targets enter $j$ before they leave $i$, implying that both zones are either patially or completely visible on both cameras.</p>

<a href='#top'>[top]</a>

<a name="4"></a><h2>Experiment</h2>
<p>Makris et al experimented their method on a set of 6 cameras monitoring street passengers (pedestrains and vehicles) for a period of 13 hours. Their result showed that Network Calibration can successfully determine the topology of the cameras as discussed in the previous section.</p>

<p>We decide to carry an experiment on the completeness of their method. More specifically, we are interested in knowing if Network Calibration can find all the valid links. Theoretically, if there's a transition between two zones, regardless of how small its probability is, running Network Calibration long enough will eventually lead to the discovery of that link. However, as running time is restricted in real world applications, the question of how much data is enough arises. It may be intuitive to think that to find a valid link, the zones of that link need to be detected and signals from these zones must be observed when performing Network Calibration. Yet, as the method is correspondence-free, trajectory information are discarded and thus one observation of a target moving along that link is not enough for the method to detect that link.</p>

<p>We construct a compter simulated environment with fixed cameras. </p>

<a href='#top'>[top]</a>

<a name="5"></a><h2>Conclusions </h2>
In summary, our results indicates that....
The advantages of the method are....
The disadvantages of the method include....
Other possible avenues for exploration include....

<a name="6"></a><h2>References</h2>
<p><a name="r1"></a>[1] Makris, D.; Ellis, T.; Black, J. "Bridging the gaps between cameras",  Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, On page(s): II-205 - II-210 Vol.2 Volume: 2, 27 June-2 July 2004 </p>
<p><a name="r2"></a>[2] Omar Javed, Zeeshan Rasheed, Khurram Shafique, Mubarak Shah, "Tracking Across Multiple Cameras With Disjoint Views", IEEE International Conference on Computer Vision, Nice, France, 2003. </p>
<p><a name="r3"></a>[3] D. Makris, T.J. Ellis, "Automatic Learning of an Activity-Based Semantic Scene Model", IEEE International Conference on Advanced Video and Signal Based Surveillance, Miami, FL, USA, pp. 183-188. July 2003.  </p>

<a href='#top'>[top]</a>
</BODY>
</html>

